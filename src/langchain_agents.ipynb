{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:22:58.960878Z",
     "start_time": "2024-04-02T08:22:58.185322Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model='gemma:2b-text')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### load the data that we want to index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b0a67c1c57f14af"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "file_path = 'data/position_titles.csv'\n",
    "loader = CSVLoader(file_path=file_path)\n",
    "titles_data = loader.load()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:22:59.163001Z",
     "start_time": "2024-04-02T08:22:58.960878Z"
    }
   },
   "id": "4d28740afc4e9e2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### index dataloader into a vectorstore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7dc6cd9296dbab4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"gemma:2b-text\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:22:59.229609900Z",
     "start_time": "2024-04-02T08:22:59.168230900Z"
    }
   },
   "id": "75f4ebeb8f37dd18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### use the embedding model to ingest documents into a vectorstore"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786243532efba182"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing text splitter...\n",
      "Starting text splitting...\n",
      "Building Vector Store...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "print(\"Initializing text splitter...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "print(\"Starting text splitting...\")\n",
    "documents = text_splitter.split_documents(titles_data)\n",
    "print(\"Building Vector Store...\")\n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "print(\"Done.\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-02T08:22:59.234957400Z"
    }
   },
   "id": "7f17ea6a7ac6dfe1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now that we have this data indexed in a vectorstore, we will create a retrieval chain. This chain will take an incoming question, look up relevant documents, then pass those documents along with the original question into an LLM and ask it to answer the original question"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bce3b32fa650b86a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### First, let's set up the chain that takes a question and the retrieved documents and generates an answer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdae969d298cef1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "context = \"\"\"You are an AI assistant that works for linkedin.\n",
    "Your job is to match between a given position title to the best matching title existing in the vector store database.\n",
    "If you can't find a good match, return null.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(f\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T19:29:47.506342300Z",
     "start_time": "2024-04-01T19:29:47.506342300Z"
    }
   },
   "id": "8dbc802972157de7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "results = []\n",
    "titles = [\"assembly crew chief at H.M. Dunn Aerospace\",\n",
    " \"RMA | Customer Service Experience |\",\n",
    " \"EXPORT SPECIALIST at DHL Express Nederland\",\n",
    " \"Came out of retirement!\",\n",
    " \"Graduate Student at University Of Iowa\",\n",
    " \"Nurse Garreth\",\n",
    " \"Graduated from Remington College-Shreveport Campus\",\n",
    " \"Senior Program Manager at Credo\",]\n",
    "for i, title in enumerate(titles):\n",
    "    response = retrieval_chain.invoke({\"input\": \"\"})\n",
    "    print(response[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-01T19:29:47.507869900Z"
    }
   },
   "id": "496967d30842478"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "46306680a35e5d35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
